{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c71bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "sys.path.append(os.path.abspath(\"N:\\\\CancerEpidem\\\\BrBreakthrough\\\\DeliveryProcess\\\\Schema_and_Derivation_utils\\\\Questionnaire\\\\R0\\\\scripts\"))\n",
    "from common_utils import get_config, createLogger, load_schema, validate_data, save_output\n",
    "from pseudo_anon_utils import load_sid_codes, pseudo_anonymize_studyid\n",
    "\n",
    "sys.path.append(os.path.abspath(\"N:\\\\CancerEpidem\\\\BrBreakthrough\\\\DeliveryProcess\\\\Schema_and_Derivation_utils\"))\n",
    "from config import Delivery_log_path, live_server\n",
    "\n",
    "sys.path.append(os.path.abspath(\"N:\\\\CancerEpidem\\\\BrBreakthrough\\\\DeliveryProcess\\\\Schema_and_Derivation_utils\\\\Pathology\\\\scripts\"))\n",
    "from building_utils import make_json_safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c66b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detects strings like 2021-01-19T00:00:00Z or 2021-01-19 00:00:00\n",
    "_ISO_DT_PREFIX = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}[T\\s].*\")\n",
    "\n",
    "def _datetime_str_to_date_str(s: str) -> str:\n",
    "    s2 = s.strip()\n",
    "    if _ISO_DT_PREFIX.match(s2):\n",
    "        return s2[:10]\n",
    "    return s\n",
    "\n",
    "def coerce_dates_by_schema_debug(\n",
    "    data: Any,\n",
    "    schema: Dict[str, Any],\n",
    "    path: str = \"<root>\",\n",
    "    *,\n",
    "    max_prints: int = 300,\n",
    "    _state: Optional[dict] = None\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Coerce ISO datetime strings to YYYY-MM-DD *only where schema expects format:'date'*.\n",
    "\n",
    "    Special handling for your exact situation:\n",
    "      - If data is a LIST and schema is an OBJECT schema, apply object schema to each list element.\n",
    "    \"\"\"\n",
    "    if _state is None:\n",
    "        _state = {\"prints\": 0, \"converted\": 0, \"date_fields_seen\": 0}\n",
    "\n",
    "    def _p(msg: str):\n",
    "        if _state[\"prints\"] < max_prints:\n",
    "            print(msg)\n",
    "            _state[\"prints\"] += 1\n",
    "\n",
    "    # --- LIST + OBJECT-SCHEMA (your case) ---\n",
    "    if isinstance(data, list) and isinstance(schema, dict) and schema.get(\"type\") == \"object\":\n",
    "        _p(f\"[LIST of records] path={path} | len={len(data)} | schema.type=object -> applying to each element\")\n",
    "        return [\n",
    "            coerce_dates_by_schema_debug(item, schema, path=f\"{path}[{i}]\", max_prints=max_prints, _state=_state)\n",
    "            for i, item in enumerate(data)\n",
    "        ]\n",
    "\n",
    "    # --- DATE leaf ---\n",
    "    if isinstance(schema, dict) and schema.get(\"format\") == \"date\":\n",
    "        _state[\"date_fields_seen\"] += 1\n",
    "        _p(f\"[DATE FIELD] path={path} | type={type(data).__name__} | value={repr(data)}\")\n",
    "        if isinstance(data, str):\n",
    "            converted = _datetime_str_to_date_str(data)\n",
    "            if converted != data:\n",
    "                _state[\"converted\"] += 1\n",
    "                _p(f\"  -> CONVERT {repr(data)} ==> {repr(converted)} (converted_count={_state['converted']})\")\n",
    "            else:\n",
    "                _p(\"  -> no change (not datetime-like string)\")\n",
    "            return converted\n",
    "        else:\n",
    "            _p(\"  -> no change (not a string)\")\n",
    "            return data\n",
    "\n",
    "    # --- OBJECT ---\n",
    "    if isinstance(data, dict):\n",
    "        props = schema.get(\"properties\") if isinstance(schema, dict) else None\n",
    "        if not isinstance(props, dict):\n",
    "            _p(f\"[OBJECT no schema.properties] path={path} | leaving unchanged\")\n",
    "            return data\n",
    "\n",
    "        out = {}\n",
    "        for k, v in data.items():\n",
    "            if k in props:\n",
    "                out[k] = coerce_dates_by_schema_debug(v, props[k], path=f\"{path}.{k}\", max_prints=max_prints, _state=_state)\n",
    "            else:\n",
    "                # note: schema has additionalProperties:false, so these would also fail validation\n",
    "                _p(f\"[KEY NOT IN SCHEMA] path={path}.{k} | type={type(v).__name__} | value={repr(v)[:120]}\")\n",
    "                out[k] = v\n",
    "        return out\n",
    "\n",
    "    # --- ARRAY schema case (not used by your Outcomes schema) ---\n",
    "    if isinstance(data, list):\n",
    "        items_schema = schema.get(\"items\") if isinstance(schema, dict) else None\n",
    "        if isinstance(items_schema, dict):\n",
    "            _p(f\"[ARRAY with items] path={path} | len={len(data)}\")\n",
    "            return [\n",
    "                coerce_dates_by_schema_debug(item, items_schema, path=f\"{path}[{i}]\", max_prints=max_prints, _state=_state)\n",
    "                for i, item in enumerate(data)\n",
    "            ]\n",
    "        _p(f\"[ARRAY no items and schema.type != object] path={path} | len={len(data)} | leaving unchanged\")\n",
    "        return data\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f870768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shift_dt(val, shift_days: int, fmt: str | None):\n",
    "    if val is None or (isinstance(val, float) and pd.isna(val)):\n",
    "        return None\n",
    "\n",
    "    dt = pd.to_datetime(val, errors=\"coerce\")\n",
    "    if pd.isna(dt):\n",
    "        return val  # leave unparseable values unchanged\n",
    "\n",
    "    dt2 = dt + pd.Timedelta(days=int(shift_days))\n",
    "\n",
    "    if fmt == \"date\":\n",
    "        return dt2.strftime(\"%Y-%m-%d\")\n",
    "    elif fmt == \"date-time\":\n",
    "        return dt2.isoformat()\n",
    "    else:\n",
    "        return dt2.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def rename_and_shift_schema_shifted_fields(data: list[dict], schema: dict, sid_df: pd.DataFrame) -> list[dict]:\n",
    "    \"\"\"\n",
    "    For each schema property ending with '_shifted':\n",
    "      - expects source field in data WITHOUT suffix (e.g. 'DOD')\n",
    "      - renames it to 'DOD_shifted'\n",
    "      - shifts the value by SIDCodes.Random days (matched on TCode)\n",
    "\n",
    "    Assumes:\n",
    "      - data is list[dict] with top-level 'TCode'\n",
    "      - sid_df has columns: 'TCode', 'Random'\n",
    "      - schema has top-level properties (flat)\n",
    "    \"\"\"\n",
    "\n",
    "    if \"TCode\" not in sid_df.columns or \"Random\" not in sid_df.columns:\n",
    "        raise KeyError(\"sid_df must contain 'TCode' and 'Random' columns.\")\n",
    "\n",
    "    tcode_to_random = sid_df.set_index(\"TCode\")[\"Random\"].astype(int).to_dict()\n",
    "\n",
    "    # Map base_field -> (shifted_field, format)\n",
    "    base_to_shifted = {}\n",
    "    for k, v in schema.get(\"properties\", {}).items():\n",
    "        if k.endswith(\"_shifted\"):\n",
    "            base = k[:-8]  # remove \"_shifted\"\n",
    "            base_to_shifted[base] = (k, v.get(\"format\"))\n",
    "\n",
    "    for rec in data:\n",
    "        tcode = rec.get(\"TCode\")\n",
    "        shift_days = int(tcode_to_random.get(tcode, 0))\n",
    "\n",
    "        for base, (shifted_name, fmt) in base_to_shifted.items():\n",
    "            # Only rename if base exists and shifted doesn't already\n",
    "            if base in rec and shifted_name not in rec:\n",
    "                rec[shifted_name] = _shift_dt(rec.pop(base), shift_days, fmt)\n",
    "            # If shifted already exists, still shift it (optional, but usually helpful)\n",
    "            elif shifted_name in rec:\n",
    "                rec[shifted_name] = _shift_dt(rec.get(shifted_name), shift_days, fmt)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bafee2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "# Assumes common_utils.get_config() is the single source of truth for servers/paths.\n",
    "config = get_config()\n",
    "\n",
    "# Choose which SQL server to use\n",
    "SERVER = config.get(live_server)\n",
    "\n",
    "logger = createLogger(\"Outcomes\", Delivery_log_path)\n",
    "\n",
    "# Data\n",
    "CSV_PATH = r'N:\\NOBACKUP\\Martina\\ndrs_data_2025\\data_outputs\\outcomes_df_20260219.csv'\n",
    "\n",
    "# Schema location\n",
    "SCHEMA_DIR = r'N:\\CancerEpidem\\BrBreakthrough\\DeliveryProcess\\Schema_and_Derivation_utils\\Questionnaire\\R0\\json_schemas\\outcomes'\n",
    "SCHEMA_NAME = 'Outcomes_Schema'\n",
    "\n",
    "# Output\n",
    "OUT_JSON_PATH = 'N:\\CancerEpidem\\BrBreakthrough\\DeliveryProcess\\Data_Output_Testing\\s5_derived\\Outcomes.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a5cb7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TCohen\\AppData\\Local\\Temp\\24\\ipykernel_19156\\1842425617.py:1: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(CSV_PATH)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Basic sanity checks\n",
    "if \"StudyID\" not in df.columns:\n",
    "    raise ValueError(\"CSV must contain a 'StudyID' column to map to TCode.\")\n",
    "\n",
    "# Ensure StudyID is int (SIDCodes expects int StudyID mapping)\n",
    "df[\"StudyID\"] = pd.to_numeric(df[\"StudyID\"], errors=\"raise\").astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7335a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid_df = load_sid_codes(live_server, logger)\n",
    "\n",
    "# Convert the dataframe rows to a list-of-dicts suitable for pseudo_anonymize_studyid\n",
    "records = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Replace StudyID with TCode, preserving all other keys\n",
    "pseudo_records = pseudo_anonymize_studyid(records, sid_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65f9ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_records = make_json_safe(pseudo_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eac2c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = load_schema(SCHEMA_DIR, SCHEMA_NAME)\n",
    "\n",
    "pseudo_records = coerce_dates_by_schema_debug(pseudo_records, schema, max_prints=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0c05c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_data = rename_and_shift_schema_shifted_fields(\n",
    "    data=pseudo_records,\n",
    "    schema=schema,\n",
    "    sid_df=sid_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f08cd2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating 116,641 items...\n",
      "100% - Validation completed in 73.68 seconds\n",
      "âœ“ All items are valid\n"
     ]
    }
   ],
   "source": [
    "# validate_data prints progress and summary\n",
    "validate_data(out_data, schema, schema_path=os.path.join(SCHEMA_DIR, f\"{SCHEMA_NAME}.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3275a269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: N:\\CancerEpidem\\BrBreakthrough\\DeliveryProcess\\Data_Output_Testing\\s5_derived\\Outcomes.json\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(os.path.dirname(OUT_JSON_PATH) or \".\", exist_ok=True)\n",
    "with open(OUT_JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(out_data, f, indent=2)\n",
    "\n",
    "print(\"Wrote:\", OUT_JSON_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
